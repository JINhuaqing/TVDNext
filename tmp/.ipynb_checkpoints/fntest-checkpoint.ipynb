{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "from collections import defaultdict as ddict\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "class OneStepOpt():\n",
    "    \"\"\"\n",
    "        I concatenate the real and image part into one vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, pUinv, fixedParas, lastTheta, **paras):\n",
    "        \"\"\"\n",
    "         Input: \n",
    "             Y: A tensor with shape, d x dF x dT\n",
    "             X: A tensor with shape, d x dF x dT\n",
    "             pUinv, the first R row of the inverse of the eigen vector matrix, R x d, complex data\n",
    "             fixedParas: The fixed parameters when optimizing, real data \n",
    "                 when update \\mu, 2R x dT\n",
    "                 when update \\nu, 2R x dF\n",
    "             lastTheta: The parameters for optimizing at the last time step, initial parameters, vector of 2R(D-1), real data\n",
    "             paras:\n",
    "                 beta: tuning parameter for iteration\n",
    "                 alp: tuning parameter for iteration\n",
    "                 rho: a vector of length (D-1)2R, real data\n",
    "                 lam: the parameter for SCAD\n",
    "                 a: the parameter for SCAD, > 1+1/beta\n",
    "                 iterNum:  integer, number of iterations\n",
    "                 iterC: decimal, stopping rule\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.paras = edict()\n",
    "        for key in paras.keys():\n",
    "            self.paras[key] = paras[key]\n",
    "            \n",
    "        self.d, self.dF, self.dT = X.shape\n",
    "        self.R2, _ = fixedParas.shape\n",
    "        self.D = int(lastTheta.shape[0]/self.R2+1)\n",
    "        self.nD = self.dF if self.D == self.dT else self.dT\n",
    "        \n",
    "        self.pUinv = pUinv\n",
    "        self.X = X.type_as(self.pUinv)\n",
    "        self.Y = Y.type_as(self.pUinv) # Make them complex\n",
    "        \n",
    "        R = int(self.R2/2)\n",
    "        self.fixedParas = torch.complex(fixedParas[:R, :], fixedParas[R:, :]).type_as(self.pUinv) # R x D\n",
    "        \n",
    "        self.lastTheta= lastTheta\n",
    "        \n",
    "        self.DiffMatSq = genDiffMatSqfn(self.R2, self.D) # R2D x R2D\n",
    "        \n",
    "        self.newVecGam = None\n",
    "        self.halfRho = None\n",
    "        self.rho = self.paras.rho\n",
    "        self.lam = self.paras.lam\n",
    "        self.a = self.paras.a \n",
    "        if \"iterNum\" not in self.paras.keys():\n",
    "            self.iterNum = None\n",
    "        else:\n",
    "            self.iterNum = self.paras.iterNum\n",
    "        if \"iterC\" not in self.paras.keys():\n",
    "            self.iterC = None\n",
    "        else:\n",
    "            self.iterC = self.paras.iterC\n",
    "            \n",
    "        self.leftMat = None\n",
    "        self.leftMatVec = None\n",
    "        self.NewXYR2Sum = None\n",
    "        \n",
    "    def obtainNewData(self):\n",
    "        pY = self.Y.permute(1, 2, 0) # dF x dT x d\n",
    "        pX = self.X.permute(1, 2, 0)\n",
    "        cNewX = pX.matmul(self.pUinv.T)  # dF x dT x R\n",
    "        if self.D == self.dF:\n",
    "            cNewY = pY.matmul(self.pUinv.T) * (1/self.fixedParas.T) # dF x dT x R\n",
    "        else:\n",
    "            cNewY = pY.matmul(self.pUinv.T) * (1/self.fixedParas.T).unsqueeze(1) # dF x dT x R\n",
    "        self.NewXr = cNewX.real\n",
    "        self.NewYr = cNewY.real\n",
    "        self.NewXi = cNewX.imag\n",
    "        self.NewYi = cNewY.imag\n",
    "        \n",
    "    \n",
    "    def updateVecGam(self):\n",
    "        \"\"\"\n",
    "            Update the Gamma matrix, first step \n",
    "        \"\"\"\n",
    "        optAxis = 1 if self.D == self.dF else 0\n",
    "        \n",
    "        if self.leftMat is None:\n",
    "            NewXSq = self.NewXr**2 + self.NewXi**2\n",
    "            NewXSqR2 = torch.cat((NewXSq, NewXSq), dim=2) # dF x dT x 2R\n",
    "            NewXSqR2Sum = NewXSqR2.sum(axis=optAxis) # dF x 2R or dT x 2R\n",
    "            self.leftMat = torch.diag(NewXSqR2Sum.flatten()).to_sparse()/self.nD +  \\\n",
    "                    self.paras.beta * self.DiffMatSq\n",
    "        \n",
    "        if self.NewXYR2Sum is None:\n",
    "            NewXY1 = self.NewXr * self.NewYr + self.NewXi * self.NewYi\n",
    "            NewXY2 = -self.NewXi * self.NewYr + self.NewXr * self.NewYi\n",
    "            NewXYR2 = torch.cat((NewXY1, NewXY2), dim=2) # dF x dT x 2R\n",
    "            self.NewXYR2Sum = NewXYR2.sum(axis=optAxis) # dF x 2R or dT x 2R\n",
    "        rightVec = self.NewXYR2Sum.flatten()/self.nD + \\\n",
    "                    DiffMatTOpt(self.rho + self.paras.beta * self.lastTheta, self.R2)\n",
    "        \n",
    "        # self.newVecGam, = torch.inverse(self.leftMat).matmul(rightVec)\n",
    "        # Better way to do so\n",
    "        self.newVecGam, _  = torch.solve(rightVec.reshape(-1, 1), self.leftMat.to_dense()) \n",
    "        self.newVecGam = self.newVecGam.reshape(-1)\n",
    "        \n",
    "    def updateVecGamApprox(self):\n",
    "        \"\"\"\n",
    "            Not good\n",
    "            Update the Gamma matrix, first step, approximately\n",
    "        \"\"\"\n",
    "        optAxis = 1 if self.D == self.dF else 0\n",
    "        \n",
    "        if self.leftMat is None:\n",
    "            NewXSq = self.NewXr**2 + self.NewXi**2\n",
    "            NewXSqR2 = torch.cat((NewXSq, NewXSq), dim=2) # dF x dT x 2R\n",
    "            NewXSqR2Sum = NewXSqR2.sum(axis=optAxis) # dF x 2R or dT x 2R\n",
    "            beVec = torch.ones(self.R2*self.D) * 2\n",
    "            beVec[:self.R2] = 1\n",
    "            beVec[-self.R2:] = 1\n",
    "            self.leftMatVec = NewXSqR2Sum.flatten()/self.nD +  self.paras.beta * beVec # this step is approximate as leftMat is not an exact diag mat\n",
    "        \n",
    "        if self.NewXYR2Sum is None:\n",
    "            NewXY1 = self.NewXr * self.NewYr + self.NewXi * self.NewYi\n",
    "            NewXY2 = -self.NewXi * self.NewYr + self.NewXr * self.NewYi\n",
    "            NewXYR2 = torch.cat((NewXY1, NewXY2), dim=2) # dF x dT x 2R\n",
    "            self.NewXYR2Sum = NewXYR2.sum(axis=optAxis) # dF x 2R or dT x 2R\n",
    "        rightVec = self.NewXYR2Sum.flatten()/self.nD + \\\n",
    "                    DiffMatTOpt(self.rho + self.paras.beta * self.lastTheta, self.R2)\n",
    "        \n",
    "        self.newVecGam = rightVec/self.leftMatVec \n",
    "        \n",
    "    def updateHRho(self):\n",
    "        \"\"\"\n",
    "            Update the vector rho at 1/2 step, second step\n",
    "        \"\"\"\n",
    "        halfRho = self.rho - self.paras.alp * self.paras.beta * (DiffMatOpt(self.newVecGam, self.R2) - self.lastTheta)\n",
    "        self.halfRho = halfRho\n",
    "       \n",
    "    \n",
    "    def updateTheta(self):\n",
    "        \"\"\"\n",
    "            Update the vector Theta, third step\n",
    "        \"\"\"\n",
    "        halfTheta = DiffMatOpt(self.newVecGam, self.R2) - self.halfRho/self.paras.beta\n",
    "        tranHTheta = halfTheta.reshape(-1, self.R2) # D-1 x 2R\n",
    "        hThetaL2Norm = tranHTheta.abs().square().sum(axis=1).sqrt() # D-1\n",
    "        normCs = torch.zeros_like(hThetaL2Norm) - 1\n",
    "        \n",
    "        normC1 = hThetaL2Norm - self.lam/self.paras.beta\n",
    "        normC1[normC1<0] = 0\n",
    "        \n",
    "        normC2 = (self.paras.beta * (self.a - 1) * hThetaL2Norm - self.a * self.lam)/(self.paras.beta * self.a - self.paras.beta -1)\n",
    "        \n",
    "        c1 = (1+1/self.paras.beta)* self.lam\n",
    "        c2 = self.a * self.lam\n",
    "        \n",
    "        normCs[hThetaL2Norm<=c1] = normC1[hThetaL2Norm<=c1]\n",
    "        normCs[hThetaL2Norm>c2] = hThetaL2Norm[hThetaL2Norm>c2]\n",
    "        normCs[normCs==-1] = normC2[normCs==-1]\n",
    "        \n",
    "        normCs[normCs!=0] = normCs[normCs!=0]/hThetaL2Norm[normCs!=0]\n",
    "        \n",
    "        self.lastTheta = (tranHTheta*normCs.reshape(-1, 1)).flatten()\n",
    "        \n",
    "    \n",
    "    def updateRho(self):\n",
    "        \"\"\"\n",
    "            Update the vector rho, fourth step\n",
    "        \"\"\"\n",
    "        newRho = self.halfRho - self.paras.alp * self.paras.beta * (DiffMatOpt(self.newVecGam, self.R2) - self.lastTheta)\n",
    "        self.rho = newRho\n",
    "        \n",
    "    \n",
    "    def __call__(self, is_approx=False, is_showProg=False):\n",
    "        self.obtainNewData()\n",
    "        \n",
    "        if self.iterNum is not None:\n",
    "            if is_showProg:\n",
    "                for i in tqdm(range(self.iterNum)):\n",
    "                    if is_approx:\n",
    "                        self.updateVecGamApprox()\n",
    "                    else:\n",
    "                        self.updateVecGam()\n",
    "                    self.updateHRho()\n",
    "                    self.updateTheta()\n",
    "                    self.updateRho()\n",
    "            else:\n",
    "                for i in range(self.iterNum):\n",
    "                    if is_approx:\n",
    "                        self.updateVecGamApprox()\n",
    "                    else:\n",
    "                        self.updateVecGam()\n",
    "                    self.updateHRho()\n",
    "                    self.updateTheta()\n",
    "                    self.updateRho()\n",
    "                #print(self.lastTheta.reshape(-1, self.R2)[0, :])\n",
    "        elif self.iterC is not None:\n",
    "            chDiff = 1e10\n",
    "            self.updateVecGam()\n",
    "            self.updateHRho()\n",
    "            self.updateTheta()\n",
    "            self.updateRho()\n",
    "            \n",
    "            lastVecGam = self.newVecGam\n",
    "            while (chDiff >= self.iterC):\n",
    "                if is_approx:\n",
    "                    self.updateVecGamApprox()\n",
    "                else:\n",
    "                    self.updateVecGam()\n",
    "                self.updateHRho()\n",
    "                self.updateTheta\n",
    "                self.updateRho()\n",
    "                chDiff = torch.norm(self.newVecGam-lastVecGam)\n",
    "                lastVecGam = self.newVecGam\n",
    "                \n",
    "            \n",
    "        if self.D == self.dF:\n",
    "            newGam = self.newVecGam.reshape(-1, self.R2) # D x 2R\n",
    "            newGamNorm = newGam.square().sum(axis=0).sqrt() # 2R\n",
    "            newGam = newGam/newGamNorm\n",
    "            self.newVecGam = newGam.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVDNextOpt():\n",
    "    \"\"\"\n",
    "        The class to implement the full procedure of TVDNext method\n",
    "    \"\"\"\n",
    "    def __init__(self, rawDat, fs, T, R, hs, **paras):\n",
    "        \"\"\"\n",
    "         Input: \n",
    "             rawDat: The raw dataset, tensor of d x dT+1\n",
    "             fs: The sampling freq of the raw dataset\n",
    "             T: Time course of the data\n",
    "             R: The rank of A mat, R << d to reduce the computational burden \n",
    "             hs: the bandwidths for the kernel regression whe estimating A matrix\n",
    "             paras:\n",
    "               For Preprocess:\n",
    "                 is_detrend: Whether detrend the raw data or not\n",
    "                 bandsCuts: the cirtical freqs to use\n",
    "                 Nord: The order of the filter\n",
    "                 q: The decimate rate\n",
    "                 \n",
    "               For A matrix:\n",
    "                 downrates: The downrate factors for freq and time, determine how many A(s_i, t_i) matrix to be summed\n",
    "                 \n",
    "               For one-step Opt:\n",
    "                 betas: list of two tuning parameter for iteration\n",
    "                 alps: list of two tuning parameter for iteration\n",
    "                 rhos: list of two vectors of length (dF-1)2R and (dT-1)2R, real data\n",
    "                 lams: list of two parameters for SCAD, for mu and nu\n",
    "                 As: list of two parameters for SCAD for mu and nu, > 1+1/beta\n",
    "                 iterNums:  integer or list of two integers, number of iterations for one-step-opt\n",
    "                 iterCs: decimal or list of two decimate, stopping rule for one-step-opt\n",
    "               \n",
    "               For the outer optimization procedure:\n",
    "                 paraMuInit: The initial value of mu parameters, along the freq axis\n",
    "                 paraNuInit: The initial value of nu parameters, along the time axis\n",
    "                 maxIter: Integer, the maximal times of iteration for the outer loop\n",
    "                 outIterC:  decimal, stopping rule for the outer loop\n",
    "        \"\"\"\n",
    "        parasDefVs = {\n",
    "                      \"is_detrend\": True, \"bandsCuts\": [[2, 3.5], [4, 7], [8, 12], [13, 30], [30, 80]], \n",
    "                      \"Nord\": None, \"q\": 10, \n",
    "                      \"downrates\": [1, 10],  \"betas\":[1, 1], \"alps\": [1, 1],  \"rhos\": None,  \"lams\": None, \n",
    "                      \"As\": [2.7, 2.7],  \"iterNums\": [1, 10], \"iterCs\": None, \"paraMuInit\": None,\n",
    "                      \"paraNuInit\": None, \"maxIter\": 100, \"outIterC\": None\n",
    "                    }\n",
    "        self.paras = edict(parasDefVs)\n",
    "        for key in paras.keys():\n",
    "            self.paras[key] = paras[key]\n",
    "            \n",
    "        if self.paras.iterCs is None:\n",
    "            self.paras.iterCs = [None, None]\n",
    "        \n",
    "            \n",
    "        self.rawDat = rawDat\n",
    "        self.fs, self.T = fs, T\n",
    "        self.R, self.R2 = R, R*2\n",
    "        self.hs = hs \n",
    "        \n",
    "        # Some none definitions\n",
    "        self.X = self.Y = self.pUinv = None\n",
    "        self.dF = self.dT = self.D = self.nD = None\n",
    "        self.lastThetaMu = self.lastTheteNu = None # Vector of 2R(dF-1)/2R(dT-1)\n",
    "        self.paraMu = self.paraNu = None # matrix of 2R x dF/dT\n",
    "        \n",
    "    def _PreProcess(self):\n",
    "        \"\"\"\n",
    "        To preprocess the raw dataset, including \n",
    "            1. Detrend, \n",
    "            2. Filter under bands\n",
    "            3. Decimate\n",
    "        \"\"\"\n",
    "        dat = signal.detrend(self.rawDat)\n",
    "        cDat = mat2Tensor(dat, fs=self.fs, q=self.paras.q)\n",
    "        # Avoid stride problem when convert numpy to tensor\n",
    "        self.X = torch.tensor(cDat.X.copy())\n",
    "        self.Y = torch.tensor(cDat.Y.copy())\n",
    "        \n",
    "    def _estAmat(self):\n",
    "        _, self.dF, self.dT = self.Y.shape\n",
    "        times = np.linspace(0, self.T, dT)\n",
    "        freqs = np.array([np.mean(bandCut) for bandCut in self.paras.bandsCuts])\n",
    "        self.Amat = GetAmatTorch(self.Y, self.X, times, freqs, self.paras.downrates, self.hs)\n",
    "        \n",
    "        res = np.linalg.eig(self.Amat)\n",
    "        Uinv = np.linalg.inv(res[1])\n",
    "        pUinv = Uinv[:self.R, :]\n",
    "        self.pUinv = torch.tensor(pUinv)\n",
    "        \n",
    "    def __call__(self, show_prog=True):\n",
    "        if self.X is None:\n",
    "            self._PreProcess()\n",
    "        if self.pUinv is None:\n",
    "            self._estAmat()\n",
    "        \n",
    "        _, self.dF, self.dT = self.X.shape\n",
    "        \n",
    "        self.D = self.dF\n",
    "        self.nD = int(self.dF*self.dT/self.D)\n",
    "        if self.paras.paraMuInit is None:\n",
    "            self.paras.paraMuInit = torch.rand(self.R2, self.dF)\n",
    "        if self.paras.paraNuInit is None:\n",
    "            self.paras.paraNuInit = torch.rand(self.R2, self.dT)\n",
    "        if self.paras.rhos is None:\n",
    "            rho1 = torch.ones(self.R2*(self.dF-1))\n",
    "            rho2 = torch.ones(self.R2*(self.dT-1))\n",
    "            self.paras.rhos = [rho1, rho2]\n",
    "            \n",
    "        \n",
    "        \n",
    "        chDiffBoth = 1e10 # Stopping rule\n",
    "        \n",
    "        lastMuTheta = DiffMatOpt(colStackFn(self.paras.paraMuInit), self.R2)\n",
    "        fixedNuMat = self.paras.paraNuInit\n",
    "        \n",
    "        stopLastMuMat = self.paras.paraMuInit\n",
    "        stopLastNuMat = self.paras.paraNuInit\n",
    "        \n",
    "        for i in range(self.paras.maxIter):\n",
    "            optMu = OneStepOpt(X=self.X, Y=self.Y, pUinv=self.pUinv, fixedParas=fixedNuMat, lastTheta=lastMuTheta, \n",
    "                               alp=self.paras.alps[0], beta=self.paras.betas[0], lam=self.paras.lams[0], \n",
    "                               a=self.paras.As[0], iterNum=self.paras.iterNums[0], rho=self.paras.rhos[0], iterC=self.paras.iterCs[0])\n",
    "            optMu()\n",
    "            \n",
    "            fixedMuMat = colStackFn(optMu.newVecGam, self.R2)\n",
    "            lastNuTheta = DiffMatOpt(colStackFn(fixedNuMat), self.R2)\n",
    "            \n",
    "            optNu = OneStepOpt(X=self.X, Y=self.Y, pUinv=self.pUinv, fixedParas=fixedMuMat, lastTheta=lastNuTheta, \n",
    "                               alp=self.paras.alps[1], beta=self.paras.betas[1], lam=self.paras.lams[1], \n",
    "                               a=self.paras.As[1], iterNum=self.paras.iterNums[1], rho=self.paras.rhos[1], iterC=self.paras.iterCs[1])\n",
    "            optNu()\n",
    "            \n",
    "            fixedNuMat = colStackFn(optNu.newVecGam, self.R2)\n",
    "            lastMuTheta = DiffMatOpt(colStackFn(fixedMuMat), self.R2)\n",
    "            \n",
    "            chDiffMu = torch.norm(stopLastMuMat-fixedMuMat)/torch.norm(stopLastMuMat)\n",
    "            chDiffNu = torch.norm(stopLastNuMat-fixedNuMat)/torch.norm(stopLastNuMat)\n",
    "            chDiffBoth = chDiffMu + chDiffNu\n",
    "            \n",
    "            stopLastMuMat = fixedMuMat\n",
    "            stopLastNuMat = fixedNuMat\n",
    "            if show_prog:\n",
    "                print(f\"Current iteration is {i+1}/{self.paras.maxIter}, the change of diff is {chDiffBoth}\")\n",
    "            if chDiffBoth <= self.paras.outIterC:\n",
    "                break\n",
    "            \n",
    "        self.paraMu = stopLastMuMat\n",
    "        self.paraNu = stopLastNuMat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = Path(\"../data\")\n",
    "datF = list(dataPath.glob(\"*.mat\"))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time course is $60$s, so freq is $600$ Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDat = loadmat(datF)\n",
    "dat = rawDat[\"DK_timecourse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 600\n",
    "R = 4\n",
    "outIterC = 1e-10\n",
    "lams = [1e2, 1e2]\n",
    "q = 100\n",
    "downrates = [1, 1]\n",
    "hs = [1, 0.1]\n",
    "T = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fOpt = TVDNextOpt(rawDat=dat, fs=fs, T=T, hs=hs, R=R, lams=lams, downrates=downrates, q=q, outIterC=outIterC, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration is 1/10, the change of diff is 2.962829556484455\n",
      "Current iteration is 2/10, the change of diff is 0.03441779624658302\n",
      "Current iteration is 3/10, the change of diff is 0.00048043776138255673\n",
      "Current iteration is 4/10, the change of diff is 4.165814612636461e-07\n",
      "Current iteration is 5/10, the change of diff is 4.895290021482425e-10\n",
      "Current iteration is 6/10, the change of diff is 5.046226601092302e-13\n"
     ]
    }
   ],
   "source": [
    "fOpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
